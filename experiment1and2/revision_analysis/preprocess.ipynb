{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"experiment2_norest\"  # set to  experiment1_rest or experiment2_norest \n",
    "rest_condition = \"norest\" if \"norest\" in folder_name else \"rest\"\n",
    "data_path = \"../data/\" + folder_name + \"/full_dataset/*.csv\"\n",
    "exact_ages = pd.read_csv(\"../data/\" + folder_name + \"/exact_ages.csv\")\n",
    "csv_files = glob.glob(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_response(x):\n",
    "    \"\"\"\n",
    "    Given a row of the dataframe, parse the response and return it as a list of [first stage choice, second stage choice]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if '[' not in x:\n",
    "            return [x]\n",
    "        else:\n",
    "            return literal_eval(str(x))\n",
    "    except:\n",
    "        return [None,None]  \n",
    "\n",
    "def is_optimal_stage(x, stage):\n",
    "    \"\"\"\n",
    "    Given a row of the dataframe, return a boolean reflecting whether the participants first or second stage choice was optimal\n",
    "    Stage: 0 for first stage, 1 for second stage\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rewardMap = literal_eval(x.rewardMap)\n",
    "        if x.isCatch or x.task_part != 'value training': return None\n",
    "        return x.response0 == max(rewardMap, key=rewardMap.get).split(',')[0]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclude participants and join data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = []\n",
    "excluded = []\n",
    "for f in csv_files:\n",
    "    df = pd.read_csv(f)\n",
    "    subject = df.loc[0][\"subject_id\"]\n",
    "    condition = df.loc[0][\"assigned_condition\"]\n",
    "\n",
    "    # calculate exclusion criteria for each subject\n",
    "    interactions = df['browser_interaction'][df['browser_interaction'].notnull()].iloc[-1].count(\"event\")\n",
    "    comprehension_retries = df.loc[(df['task_part'] == 'comp_question') & (df['correct'] == False)].shape[0]\n",
    "    dots_missed = 0\n",
    "    if rest_condition == \"rest\":\n",
    "        dots_missed = df['numberMissed'].sum()\n",
    "    catch_correct = df[(df['isCatch'] == True) & (df['task_part']!=\"catch practice\")][\"correct\"].sum()\n",
    "    task_timeouts = df[(df['trial_type'] == \"revaluation\") & (df['environment'] != 'space')]['timeout'].mean()\n",
    "    memory_timeouts = df.loc[(df['trial_type'] == \"memory-trial\")]['timeout'].mean()\n",
    "    test_timeouts = df[(df['task_part'] == \"first stage test\")]['timeout'].mean()\n",
    "    block1_lasthalf_accuracy = df[(df['order'] == 1) & (df['task_part'] == 'value training') & (df['isCatch']==False)].tail(21)['correct'].mean()\n",
    "    block2_lasthalf_accuracy = df[(df['order'] == 2) & (df['task_part'] == 'value training') & (df['isCatch']==False)].tail(21)['correct'].mean()\n",
    "    \n",
    "    # exclude subjects based on criteria\n",
    "    if interactions > 20 or task_timeouts > 0.15 or memory_timeouts>0.15 or comprehension_retries > 4 or catch_correct<11 or block1_lasthalf_accuracy<0.75 or block2_lasthalf_accuracy<0.75 or (rest_condition == \"rest\" and dots_missed > 4):\n",
    "        excluded.append({'subject':subject,'catch_correct':catch_correct, 'block1_second_half_accuracy':block1_lasthalf_accuracy, 'block2_second_half_accuracy':block2_lasthalf_accuracy, 'task_timeouts':task_timeouts, 'memory_timeouts':memory_timeouts, 'comprehension_retries':comprehension_retries, 'interactions':interactions, 'dots_missed': dots_missed})\n",
    "    else:\n",
    "        # keep only relevant columns\n",
    "        filtered = df[['subject_id','task_part', 'rt', 'timeout', 'stimulus', 'response','environment','score', 'isCatch', 'correct', 'condition', 'order', 'rewardMap','trial_num', 'ground_truth', 'age']]\n",
    "        filtered = filtered[filtered['task_part'].isin(['value training', 'revaluation','first stage test','second stage test', 'memory'])]\n",
    "        \n",
    "        # add task condition and age info\n",
    "        filtered['subject_condition'] = condition\n",
    "        filtered['rest'] = rest_condition\n",
    "        filtered['age'] = float(exact_ages[exact_ages['subject_id'] == int(subject)].iloc[0]['Age'])\n",
    "\n",
    "        # rename values for block_condition to Revaluation and Control\n",
    "        filtered['condition'] = filtered['condition'].replace({'original': 'Control', 'revaluation': 'Revaluation'})\n",
    "\n",
    "        # reformatting trial_num and response data\n",
    "        filtered['trial_num'] = filtered['trial_num'].astype('Int64') // 2      \n",
    "        response_list = filtered['response'].apply(lambda x: reformat_response(x)).values.tolist()\n",
    "        response_df = pd.DataFrame(response_list).add_prefix('response')  \n",
    "        filtered = filtered.reset_index().join(response_df).drop('response', axis=1)\n",
    "        \n",
    "        # compute is_optimal_first, is_optimal_second for each trial\n",
    "        first = filtered.apply(lambda x: is_optimal_stage(x,0), axis=1)\n",
    "        second = filtered.apply(lambda x: is_optimal_stage(x,1), axis=1)\n",
    "        filtered = filtered.merge(first.rename(\"is_optimal_first\"),left_index=True, right_index=True)\n",
    "        filtered = filtered.merge(second.rename(\"is_optimal_second\"),left_index=True, right_index=True)\n",
    "        \n",
    "        # add participants data to filtered_data\n",
    "        filtered_data.append(filtered)\n",
    "\n",
    "# concatenate all subjects data\n",
    "filtered_data = pd.concat(filtered_data, ignore_index=True)\n",
    "\n",
    "# add column for categorical age\n",
    "filtered_data['categorical_age'] = pd.cut(filtered_data['age'], bins=[7,13,18,24], labels=['Children','Adolescents','Adults'])\n",
    "\n",
    "# rename columns \"order\" to \"block_order\" and \"condition\" to \"block_condition\"\n",
    "filtered_data = filtered_data.rename(columns={'order':'block_order', 'condition':'block_condition'})\n",
    "\n",
    "# save data about excluded participants\n",
    "excluded = pd.DataFrame(excluded)\n",
    "excluded.to_csv('../data/' + folder_name + '/preprocessed/excluded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data to assess optimal choices during learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only non-catch learning trials\n",
    "learning_data = filtered_data[(filtered_data['task_part']=='value training') & (filtered_data['isCatch']==False)].copy() \n",
    "\n",
    "# reset trial number after removing catch \n",
    "learning_data['trial_num'] = learning_data.groupby(['subject_id', 'block_condition']).cumcount() + 1    \n",
    "\n",
    " # get binned trial num for graphing smooth learning curves\n",
    "learning_data['trial_bin'] = learning_data.groupby(['subject_id','block_order']).cumcount() // 5 * 5     \n",
    "\n",
    "# keep only trials where participants did not time out        \n",
    "learning_data = learning_data[learning_data['timeout']==False]    \n",
    "\n",
    "# binary optimal score metric for performance\n",
    "learning_data.to_csv('../data/' + folder_name + '/preprocessed/learning_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To assess age differences in first-stage vs second-stage choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_data_by_stage = learning_data.copy().melt(\n",
    "    id_vars=['subject_id','age','trial_num','block_condition','block_order'],\n",
    "    value_vars=['is_optimal_first', 'is_optimal_second'],\n",
    "    var_name='stage',\n",
    "    value_name='optimal'\n",
    ")\n",
    "\n",
    "learning_data_by_stage['stage'] = learning_data_by_stage['stage'].replace({'is_optimal_first': 'First', 'is_optimal_second': 'Second'})\n",
    "learning_data_by_stage.to_csv('../data/' + folder_name + '/preprocessed/learning_data_by_stage.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To assess optimal choices during relearning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "relearning_data = filtered_data[filtered_data['task_part']=='revaluation'].copy()\n",
    "\n",
    "# calculate trial number per second stage state\n",
    "relearning_data['trial'] = relearning_data.groupby(['subject_id', 'stimulus'])['stimulus'].cumcount()\n",
    "\n",
    "# keep only trials where participants did not time out        \n",
    "relearning_data = relearning_data[relearning_data['timeout']==False]    \n",
    "\n",
    "relearning_data.to_csv('../data/' + folder_name + '/preprocessed/relearning_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To assess choice updating at test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reval_magnitude(condition):\n",
    "    \"\"\"\n",
    "    Given a value for block condition, return the revaluation magnitude for each subject in that condition\n",
    "    \"\"\"\n",
    "    # Get proportion of correct first-stage choices in the last 10 trials of value learning for each subject (excluding catch trials and timeouts)\n",
    "    correct_before = learning_data[learning_data['block_condition']==condition].groupby('subject_id').tail(10).groupby('subject_id')['is_optimal_first'].mean()\n",
    "\n",
    "    # Get proportion of matching first-stage choices at test (excluding timeouts)\n",
    "    after = filtered_data[(filtered_data['task_part'] == 'first stage test') & (filtered_data['block_condition'] == condition) & (filtered_data['timeout'] == False)]\n",
    "    match_after = after.groupby('subject_id')['correct'].mean()\n",
    "    \n",
    "    # For revaluation condition, 'correct' first stage choice does not match correct first stage choice during learning\n",
    "    if condition == 'Revaluation':\n",
    "        match_after = 1 - match_after\n",
    "   \n",
    "    reval_magnitude = correct_before - match_after\n",
    "    return reval_magnitude.rename(condition)\n",
    "\n",
    "# get revaluation magnitude for each subject and condition\n",
    "reval_reval_magnitude = get_reval_magnitude('Revaluation')\n",
    "control_reval_magnitude = get_reval_magnitude('Control')\n",
    "reval_results = pd.concat([reval_reval_magnitude, control_reval_magnitude], axis=1)\n",
    "reval_results = reval_results.reset_index().melt(id_vars=['subject_id'], value_vars=['Revaluation', 'Control'], var_name='block_condition', value_name='reval_score')\n",
    "\n",
    "# add metadata on block_order, environment, rest, and age\n",
    "metadata = filtered_data[['age','categorical_age','block_order','environment','subject_id','block_condition']].drop_duplicates(subset=['subject_id', 'block_condition'])\n",
    "reval_results = reval_results.merge(metadata, on=['subject_id', 'block_condition'], how='left')\n",
    "reval_results['rest'] = \"No Rest\" if rest_condition == \"norest\" else \"Rest\"\n",
    "\n",
    "# Add participant's second stage test accuracy for each block condition\n",
    "second_stage_test = filtered_data[(filtered_data['task_part'] == 'second stage test') & (filtered_data['timeout'] == False)].groupby([\"subject_id\",\"block_condition\"])['correct'].mean().reset_index()\n",
    "second_stage_test = second_stage_test.rename(columns={'correct': 'second_stage_test'})\n",
    "reval_results = pd.merge(reval_results,second_stage_test,on=['subject_id','block_condition'])\n",
    "\n",
    "# Add participant's last 10 learning accuracy for each block condition\n",
    "last_10_accuracy = learning_data.groupby(['subject_id','block_condition']).tail(10).groupby(['subject_id','block_condition'])['correct'].mean().reset_index()\n",
    "last_10_accuracy = last_10_accuracy.rename(columns={'correct': 'last_10_accuracy'})\n",
    "reval_results = pd.merge(reval_results,last_10_accuracy,on=['subject_id','block_condition'])\n",
    "\n",
    "reval_results.to_csv('../data/' + folder_name + '/preprocessed/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To assess memory for first-stage images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_data = filtered_data[(filtered_data['task_part']=='memory') & (filtered_data['timeout'] == False)].copy()\n",
    "memory_data['environment'] = memory_data['stimulus'].str.split('/').str[3]\n",
    "memory_data = memory_data[memory_data['environment'] != 'space']\n",
    "memory_data = memory_data.drop(['block_condition', 'block_order'], axis=1)\n",
    "metadata = filtered_data[['block_order','environment','subject_id','block_condition']].drop_duplicates()\n",
    "memory_data = memory_data.merge(metadata, on=['subject_id', 'environment'], how='left')\n",
    "memory_data.to_csv('../data/' + folder_name + '/preprocessed/memory_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dce927224107569668b4f57f1e9f97b39c55aeb52b23c7f856ebe1aabdcc49cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
