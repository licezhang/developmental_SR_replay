{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_condition = \"norest\"\n",
    "folder_name = \"experiment2_norest\"\n",
    "data_path = \"../data/\" + folder_name + \"/full_dataset/*.csv\"\n",
    "exact_ages = pd.read_csv(\"../data/\" + folder_name + \"/exact_ages.csv\")\n",
    "csv_files = glob.glob(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_optimal_first(x):\n",
    "    try:\n",
    "        rewardMap = literal_eval(x.rewardMap)\n",
    "        if x.isCatch or x.task_part != 'value training': return None\n",
    "        return x.response0 == max(rewardMap, key=rewardMap.get).split(',')[0]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def optimal_score(x):\n",
    "    try:\n",
    "        rewardMap = literal_eval(x.rewardMap)\n",
    "        if x.isCatch or x.task_part != 'value training': return None\n",
    "        return max(rewardMap.values())\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def is_optimal_second(x):\n",
    "    try:\n",
    "        rewardMap = literal_eval(x.rewardMap)\n",
    "        subset = {k: v for k, v in rewardMap.items() if x.response0 in k}\n",
    "        if x.isCatch or x.task_part != 'value training': return None\n",
    "        return x.response1 == max(subset, key=subset.get).split(',')[1]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def reformat_rt(x):\n",
    "    try:\n",
    "        if type(literal_eval(str(x)))==int:\n",
    "            return [literal_eval(str(x))]\n",
    "        else:\n",
    "            return literal_eval(str(x)) \n",
    "    except:\n",
    "        return [None,None]   \n",
    "    \n",
    "def reformat_response(x):\n",
    "    try:\n",
    "        if '[' not in x:\n",
    "            return [x]\n",
    "        else:\n",
    "            return literal_eval(str(x))\n",
    "    except:\n",
    "        return [None,None]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = []\n",
    "excluded = []\n",
    "\n",
    "for f in csv_files:\n",
    "    df = pd.read_csv(f)\n",
    "    subject = df.loc[0][\"subject_id\"]\n",
    "    condition = df.loc[0][\"assigned_condition\"]\n",
    "    if 'bonus' in df:\n",
    "        # calculate exclusion criteria for each subject\n",
    "        interactions = df['browser_interaction'][df['browser_interaction'].notnull()].iloc[-1].count(\"event\")\n",
    "        comprehension_retries = df.loc[(df['task_part'] == 'comp_question') & (df['correct'] == False)].shape[0]\n",
    "        dots_missed = 0\n",
    "        if rest_condition == \"rest\":\n",
    "            dots_missed = df['numberMissed'].sum()\n",
    "        catch_correct = df[(df['isCatch'] == True) & (df['task_part']!=\"catch practice\")][\"correct\"].sum()\n",
    "        task_timeouts = df[(df['trial_type'] == \"revaluation\") & (df['environment'] != 'space')]['timeout'].mean()\n",
    "        memory_timeouts = df.loc[(df['trial_type'] == \"memory-trial\")]['timeout'].mean()\n",
    "        test_timeouts = df[(df['task_part'] == \"first stage test\")]['timeout'].mean()\n",
    "        block1_lasthalf_accuracy = df[(df['order'] == 1) & (df['task_part'] == 'value training') & (df['isCatch']==False)].tail(21)['correct'].mean()\n",
    "        block2_lasthalf_accuracy = df[(df['order'] == 2) & (df['task_part'] == 'value training') & (df['isCatch']==False)].tail(21)['correct'].mean()\n",
    "       \n",
    "        if interactions > 20 or task_timeouts > 0.15 or memory_timeouts>0.15 or comprehension_retries > 4 or catch_correct<11 or block1_lasthalf_accuracy<0.75 or block2_lasthalf_accuracy<0.75 or (rest_condition == \"rest\" and dots_missed > 4):\n",
    "            excluded.append({'subject':subject,'catch_correct':catch_correct, 'block1_second_half_accuracy':block1_lasthalf_accuracy, 'block2_second_half_accuracy':block2_lasthalf_accuracy, 'task_timeouts':task_timeouts, 'memory_timeouts':memory_timeouts, 'comprehension_retries':comprehension_retries, 'interactions':interactions, 'dots_missed': dots_missed})\n",
    "        else:\n",
    "            # keep only relevant columns\n",
    "            filtered = df[['subject_id','task_part', 'rt', 'timeout', 'stimulus', 'response','environment','score', 'isCatch', 'correct', 'condition', 'order', 'rewardMap','trial_num', 'ground_truth', 'age', 'gender']]\n",
    "            filtered = filtered[filtered['task_part'].isin(['value training', 'revaluation','first stage test','second stage test', 'memory'])]\n",
    "            \n",
    "            # add task condition and age info\n",
    "            filtered['subject_condition'] = condition\n",
    "            filtered['rest'] = rest_condition\n",
    "            filtered['age'] = float(exact_ages[exact_ages['subject_id'] == int(subject)].iloc[0]['Age'])\n",
    "\n",
    "            # reformatting trial_num, RT, and response data\n",
    "            filtered['trial_num'] = filtered['trial_num'].astype('Int64') // 2\n",
    "            rt_list = filtered['rt'].apply(lambda x: reformat_rt(x)).values.tolist()\n",
    "            rt_df = pd.DataFrame(rt_list).add_prefix('rt')  \n",
    "            filtered = filtered.reset_index().join(rt_df).drop('rt', axis=1)        \n",
    "            response_list = filtered['response'].apply(lambda x: reformat_response(x)).values.tolist()\n",
    "            response_df = pd.DataFrame(response_list).add_prefix('response')  \n",
    "            filtered = filtered.reset_index().join(response_df).drop('response', axis=1)\n",
    "            \n",
    "            # compute is_optimal_first, is_optimal_second, and optimal_score for each trial\n",
    "            first = filtered.apply(lambda x: is_optimal_first(x), axis=1)\n",
    "            second = filtered.apply(lambda x: is_optimal_second(x), axis=1)\n",
    "            filtered = filtered.merge(first.rename(\"is_optimal_first\"),left_index=True, right_index=True)\n",
    "            filtered = filtered.merge(second.rename(\"is_optimal_second\"),left_index=True, right_index=True)\n",
    "            filtered['optimal_score'] = filtered.apply(optimal_score, axis=1)\n",
    "            \n",
    "            filtered_data.append(filtered)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "filtered_data = pd.concat(filtered_data, ignore_index=True)\n",
    "filtered_data['categorical_age'] = pd.cut(filtered_data['age'], bins=[7,13,18,24], labels=['Children','Adolescents','Adults'])\n",
    "# rename columns \"order\" to \"block_order\" and \"condition\" to \"block_condition\"\n",
    "filtered_data = filtered_data.rename(columns={'order':'block_order', 'condition':'block_condition'})\n",
    "\n",
    "excluded = pd.DataFrame(excluded)\n",
    "excluded.to_csv('../data/' + folder_name + '/preprocessed/excluded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To assess optimal choices during learning\n",
    "learning_data = filtered_data[(filtered_data['task_part']=='value training')&(filtered_data['isCatch']==False)].copy() # keep only non-catch learning trials\n",
    "learning_data['trial_num'] = learning_data.groupby(['subject_id', 'block_condition']).cumcount() + 1                  # reset trial number after removing catch \n",
    "learning_data['trial_bin'] = learning_data.groupby(['subject_id','block_order']).cumcount() // 5 * 5                  # get binned trial num for graphing smooth learning curve\n",
    "learning_data = learning_data[learning_data['timeout']==False]                                                  # keep only trials where participants did not time out\n",
    "learning_data['is_optimal'] = learning_data['score'] == learning_data['optimal_score']                          # binary optimal score metric for performance\n",
    "learning_data.to_csv('../data/' + folder_name + '/preprocessed/learning_data1.csv')\n",
    "\n",
    "# To assess age differences in first-stage vs second-stage choices\n",
    "learning_data_2 = learning_data.copy().melt(\n",
    "    id_vars=['subject_id','age','trial_num','block_condition','block_order'],\n",
    "    value_vars=['is_optimal_first', 'is_optimal_second'],\n",
    "    var_name='stage',\n",
    "    value_name='optimal'\n",
    ")\n",
    "learning_data_2['stage'] = learning_data_2['stage'].replace({'is_optimal_first': 'First', 'is_optimal_second': 'Second'})\n",
    "learning_data_2.to_csv('../data/' + folder_name + '/preprocessed/learning_data2.csv')\n",
    "\n",
    "# To assess optimal choices during relearning\n",
    "relearning_data = filtered_data[filtered_data['task_part']=='revaluation'].copy()\n",
    "relearning_data['trial'] = relearning_data.groupby(['subject_id', 'stimulus'])['stimulus'].cumcount()   # Calculate trial number per second stage state\n",
    "relearning_data.to_csv('../data/' + folder_name + '/preprocessed/relearning_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata about each subject block (order, stimuli)\n",
    "block_conditions = filtered_data.groupby(['subject_id','block_condition'],as_index=False).first()[['subject_id','block_condition','environment','block_order']]\n",
    "block_conditions['block_condition'] = block_conditions['block_condition'].apply(lambda x: \"Control\" if x=='original' else \"Revaluation\")\n",
    "\n",
    "# get age info for each subject\n",
    "demographics = filtered_data.groupby('subject_id').first()[['age','gender','categorical_age']]\n",
    "\n",
    "learning_first_stage_accuracy = learning_data.groupby(['subject_id','block_condition']).tail(10).groupby(['subject_id','block_condition'])['is_optimal_first'].mean().reset_index()\n",
    "last_10_accuracy = learning_data.groupby(['subject_id','block_condition']).tail(10).groupby(['subject_id','block_condition'])['is_optimal'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_data = filtered_data[filtered_data['task_part']=='memory'].copy()\n",
    "memory_data['environment'] = memory_data['stimulus'].str.split('/').str[3]\n",
    "memory_data = memory_data[memory_data['environment'] != 'space']\n",
    "memory_data = memory_data.drop(['block_condition', 'block_order'], axis=1)\n",
    "memory_data = memory_data.merge(block_conditions,on=['subject_id','environment'])\n",
    "memory_data.to_csv('../data/' + folder_name + '/preprocessed/memory_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reval_magnitude(filtering, name):\n",
    "    before = filtered_data[(filtered_data['task_part'] == 'value training') & filtering & (filtered_data['isCatch']==False)].groupby('subject_id').tail(10).copy()\n",
    "    after = filtered_data[(filtered_data['task_part'] == 'first stage test') & filtering].copy()\n",
    "    reward_map_before = before.groupby('subject_id').first()['rewardMap'].apply(lambda x: literal_eval(x))\n",
    "    correct_response = reward_map_before.apply(lambda x: max(x, key=x.get).split(\",\")[0])\n",
    "    true_accuracy_before = before.groupby('subject_id')['correct'].mean()\n",
    "    before['correct'] = before.apply(lambda x: x.response0 == correct_response[x.subject_id], axis=1)\n",
    "    after['correct'] = after.apply(lambda x: x.response0 == correct_response[x.subject_id], axis=1)\n",
    "    correct_before = before.groupby('subject_id')['correct'].mean()\n",
    "    match_after = after.groupby('subject_id')['correct'].mean()\n",
    "    reval_magnitude = correct_before - match_after\n",
    "    single_reval = after.groupby('subject_id').head(1).apply(lambda x: x.response0 != correct_response[x.subject_id], axis=1)\n",
    "    single_reval.index = after.groupby('subject_id').head(1)['subject_id']\n",
    "    return reval_magnitude.rename(name), true_accuracy_before.rename(name+'_correct_before'), single_reval.rename(name+'_single')\n",
    "\n",
    "reval_reval_magnitude, reval_correct_before, reval_single = get_reval_magnitude(filtered_data['block_condition']=='revaluation', 'Revaluation')\n",
    "control_reval_magnitude, control_correct_before, control_single = get_reval_magnitude(filtered_data['block_condition']=='original', 'Control')\n",
    "first_reval_magnitude, _, _ = get_reval_magnitude(filtered_data['block_order']==1, 'first')\n",
    "second_reval_magnitude, _, _ = get_reval_magnitude(filtered_data['block_order']==2, 'second')\n",
    "reval_results = pd.concat([reval_reval_magnitude, control_reval_magnitude, first_reval_magnitude, second_reval_magnitude, reval_correct_before, control_correct_before, reval_single, control_single], axis=1)\n",
    "reval_results = pd.merge(reval_results,demographics, on=\"subject_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x_/2rt9php14l77064t1fz9yq800000gp/T/ipykernel_6941/2014174337.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  participant_data_processed['reval_score'] = reval_results['Revaluation']\n",
      "/var/folders/x_/2rt9php14l77064t1fz9yq800000gp/T/ipykernel_6941/2014174337.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  participant_data_processed['reval_single'] = reval_results['Revaluation_single']\n",
      "/var/folders/x_/2rt9php14l77064t1fz9yq800000gp/T/ipykernel_6941/2014174337.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  participant_data_processed['last_10_accuracy'] = reval_results['Revaluation_correct_before']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>block_condition</th>\n",
       "      <th>categorical_age</th>\n",
       "      <th>reval_score</th>\n",
       "      <th>reval_single</th>\n",
       "      <th>last_10_accuracy</th>\n",
       "      <th>environment</th>\n",
       "      <th>block_order</th>\n",
       "      <th>rest</th>\n",
       "      <th>second_stage_accuracy</th>\n",
       "      <th>revaluation_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8171</th>\n",
       "      <td>10.58</td>\n",
       "      <td>Revaluation</td>\n",
       "      <td>Children</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>canyon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No Rest</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8175</th>\n",
       "      <td>11.64</td>\n",
       "      <td>Revaluation</td>\n",
       "      <td>Children</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ocean</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No Rest</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8191</th>\n",
       "      <td>15.44</td>\n",
       "      <td>Revaluation</td>\n",
       "      <td>Adolescents</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>canyon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No Rest</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8200</th>\n",
       "      <td>19.77</td>\n",
       "      <td>Revaluation</td>\n",
       "      <td>Adults</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ocean</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No Rest</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8201</th>\n",
       "      <td>19.34</td>\n",
       "      <td>Revaluation</td>\n",
       "      <td>Adults</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ocean</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No Rest</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13778</th>\n",
       "      <td>18.21</td>\n",
       "      <td>Control</td>\n",
       "      <td>Adults</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ocean</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No Rest</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13782</th>\n",
       "      <td>18.60</td>\n",
       "      <td>Control</td>\n",
       "      <td>Adults</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>canyon</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No Rest</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14425</th>\n",
       "      <td>18.51</td>\n",
       "      <td>Control</td>\n",
       "      <td>Adults</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ocean</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No Rest</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14427</th>\n",
       "      <td>22.42</td>\n",
       "      <td>Control</td>\n",
       "      <td>Adults</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>canyon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No Rest</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14485</th>\n",
       "      <td>16.34</td>\n",
       "      <td>Control</td>\n",
       "      <td>Adolescents</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>canyon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No Rest</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              age block_condition categorical_age  reval_score  reval_single  \\\n",
       "subject_id                                                                     \n",
       "8171        10.58     Revaluation        Children         0.50         False   \n",
       "8175        11.64     Revaluation        Children         0.25         False   \n",
       "8191        15.44     Revaluation     Adolescents        -0.10         False   \n",
       "8200        19.77     Revaluation          Adults         0.50         False   \n",
       "8201        19.34     Revaluation          Adults         0.00         False   \n",
       "...           ...             ...             ...          ...           ...   \n",
       "13778       18.21         Control          Adults         0.00         False   \n",
       "13782       18.60         Control          Adults         0.00         False   \n",
       "14425       18.51         Control          Adults         0.25         False   \n",
       "14427       22.42         Control          Adults         0.00         False   \n",
       "14485       16.34         Control     Adolescents         0.00         False   \n",
       "\n",
       "            last_10_accuracy environment  block_order     rest  \\\n",
       "subject_id                                                       \n",
       "8171                     1.0      canyon          1.0  No Rest   \n",
       "8175                     1.0       ocean          1.0  No Rest   \n",
       "8191                     0.9      canyon          1.0  No Rest   \n",
       "8200                     1.0       ocean          1.0  No Rest   \n",
       "8201                     1.0       ocean          1.0  No Rest   \n",
       "...                      ...         ...          ...      ...   \n",
       "13778                    1.0       ocean          1.0  No Rest   \n",
       "13782                    1.0      canyon          2.0  No Rest   \n",
       "14425                    1.0       ocean          1.0  No Rest   \n",
       "14427                    1.0      canyon          1.0  No Rest   \n",
       "14485                    1.0      canyon          1.0  No Rest   \n",
       "\n",
       "            second_stage_accuracy  revaluation_accuracy  \n",
       "subject_id                                               \n",
       "8171                       0.9375              0.888889  \n",
       "8175                       0.4375              0.694444  \n",
       "8191                       0.7500              0.944444  \n",
       "8200                       0.4375              0.805556  \n",
       "8201                       1.0000              0.888889  \n",
       "...                           ...                   ...  \n",
       "13778                      0.9375              0.888889  \n",
       "13782                      1.0000              0.916667  \n",
       "14425                      1.0000              0.888889  \n",
       "14427                      1.0000              0.944444  \n",
       "14485                      0.8750              0.888889  \n",
       "\n",
       "[240 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reval_results['block_condition'] = 'Revaluation'\n",
    "participant_data_processed = reval_results[['age', 'block_condition','categorical_age']]\n",
    "participant_data_processed['reval_score'] = reval_results['Revaluation']\n",
    "participant_data_processed['reval_single'] = reval_results['Revaluation_single']\n",
    "participant_data_processed['last_10_accuracy'] = reval_results['Revaluation_correct_before']\n",
    "participant_data_processed = participant_data_processed.reset_index()\n",
    "control = reval_results.reset_index()\n",
    "control['block_condition'] = 'Control'\n",
    "control['reval_score'] = control['Control']\n",
    "control['reval_single'] = control['Control_single']\n",
    "control['last_10_accuracy'] = control['Control_correct_before']\n",
    "participant_data_processed = pd.concat([participant_data_processed,control[['subject_id', 'age', 'block_condition', 'reval_score','last_10_accuracy','categorical_age','reval_single']]])\n",
    "participant_data_processed = participant_data_processed.merge(block_conditions,on=['subject_id','block_condition'])\n",
    "rest_name = \"No Rest\"\n",
    "if rest_condition == \"rest\":\n",
    "    rest_name = \"Rest\"\n",
    "participant_data_processed['rest'] = rest_name\n",
    "participant_data_processed['second_stage_accuracy'] = filtered_data.where(filtered_data['task_part'] == 'second stage test').groupby('subject_id')['correct'].mean()\n",
    "participant_data_processed['revaluation_accuracy'] = filtered_data.where(filtered_data['task_part'] == 'revaluation').groupby('subject_id')['correct'].mean()\n",
    "participant_data_processed = participant_data_processed.set_index('subject_id')\n",
    "participant_data_processed['second_stage_accuracy'] = filtered_data.where(filtered_data['task_part'] == 'second stage test').groupby('subject_id')['correct'].mean()\n",
    "participant_data_processed['revaluation_accuracy'] = filtered_data.where(filtered_data['task_part'] == 'revaluation').groupby('subject_id')['correct'].mean()\n",
    "\n",
    "second_stage_test = filtered_data[filtered_data['task_part'] == 'second stage test'].groupby([\"subject_id\",\"block_condition\"])['correct'].mean().reset_index()\n",
    "second_stage_test['block_condition'] = second_stage_test['block_condition'].apply(lambda x: \"Control\" if x=='original' else \"Revaluation\")\n",
    "pd.merge(participant_data_processed,second_stage_test,on=['subject_id','block_condition'])\n",
    "\n",
    "participant_data_processed.to_csv('../data/' + folder_name + '/preprocessed/data.csv')\n",
    "participant_data_processed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "050487248c4b83914858675c399d665afa72501313530572bee936246e336b83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
